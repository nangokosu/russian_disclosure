{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entry(year,year_dict,start,end):\n",
    "    '''Finds all the necessary elements to create a dictionary entry for each observation'''\n",
    "    root=\"https://declarator.org\"\n",
    "    # We need to use the AJAX url to get the full list of people\n",
    "    url=f\"https://declarator.org/office/5/{year_dict[year]}/ajax/?start={start}&end={end}&sort_order=\"\n",
    "    r=requests.get(\"http://localhost:8050/render.html\",params={\"url\":url})\n",
    "    html=lxml.html.fromstring(r.content)\n",
    "    person=html.xpath('//div[@class=\"person_name activetext\"]')\n",
    "    if len(person)>0:\n",
    "        person=person[0]\n",
    "        person_url=root+person.xpath('./a/@href')[0]\n",
    "        family_name=person.xpath('./a/div[@class=\"family_name\"]/h4/text()')[0]\n",
    "        name=person.xpath('./a/h4/text()')[0]\n",
    "        position=html.xpath('//div[2]/i/text()')[0]\n",
    "        party_affiliation=html.xpath('//div[@class=\"party\"]/text()')\n",
    "        if len(party_affiliation)>0:\n",
    "            party_affiliation=party_affiliation[0].strip()\n",
    "        else:\n",
    "            party_affiliation=None\n",
    "        assets=html.xpath('//p//text()')\n",
    "        return {\"year\":year,\"family_name\":family_name,\"name\":name,\"position\":position,\"party_affiliation\":party_affiliation,\"assets\":assets,\"url\":person_url}\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(list_of_words):\n",
    "    '''Preliminary text cleaning for asset_value extraction'''\n",
    "    clean_list=[re.sub(r\"\\n\",\"\",word).strip() for word in list_of_words]\n",
    "    clean_list=[re.sub(r\" m\",\" sqm\",word).strip() for word in clean_list]\n",
    "    clean_list=[item for item in clean_list if len(item)>0 and item!=\"2\"]\n",
    "    return clean_list\n",
    "\n",
    "def clean_text_details(list_of_words):\n",
    "    '''Fixes text for asset_value extraction'''\n",
    "    clean_list=clean_text(list_of_words)\n",
    "    new_list=[]\n",
    "    i=0\n",
    "    while i <=len(clean_list)-1:\n",
    "        if i==len(clean_list)-1:\n",
    "            new_list.append(clean_list[i])\n",
    "            i+=1\n",
    "        elif clean_list[i+1][0]==\"(\" or clean_list[i+1][0]==\",\":\n",
    "            new_list.append(clean_list[i]+\" \"+clean_list[i+1])\n",
    "            i+=2\n",
    "        else:\n",
    "            new_list.append(clean_list[i])\n",
    "            i+=1\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(year,family_name,name,title,party,url,cleaned_list):\n",
    "    '''Creates clean dictionary for each entry where asset_type and asset_value are separated'''\n",
    "    index_list=[]\n",
    "    for item in [\"Income\",\"Real estate\",\"Transport\",\"Accounts\"]:\n",
    "        try:\n",
    "            index=cleaned_list.index(item)\n",
    "            index_list.append(index)\n",
    "        except:\n",
    "            continue\n",
    "    final_output=[]\n",
    "    index_list.append(len(cleaned_list))\n",
    "    for i in range(len(index_list)-1):\n",
    "        begin=index_list[i]+1\n",
    "        end=index_list[i+1]\n",
    "        span=cleaned_list[begin:end]\n",
    "        for item in span:\n",
    "            return_list={}\n",
    "            return_list['year']=year\n",
    "            return_list['last_name']=family_name\n",
    "            return_list['first_name']=name\n",
    "            return_list[\"position\"]=title\n",
    "            return_list[\"url\"]=url\n",
    "            return_list[\"party\"]=party\n",
    "            return_list[\"asset_type\"]=cleaned_list[index_list[i]]\n",
    "            return_list[\"asset_value\"]=item\n",
    "            final_output.append(return_list)  \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2=\"https://declarator.org/office/5\"\n",
    "root_2=\"https://declarator.org\"\n",
    "r2=requests.get(\"http://localhost:8050/render.html\",params={\"url\":url_2})\n",
    "html2=lxml.html.fromstring(r2.content)\n",
    "new_dict={}\n",
    "for element in html2.xpath('//tr')[3:]:\n",
    "    year=element.xpath('./td[position()=1]/text()')[0]\n",
    "    element_2=element.xpath('./td[position()=2]//ul[@class=\"list-inline activetext\"]/li/a')[0]\n",
    "    if element_2.xpath('./text()')[0].strip()==\"Anti-corruption declaration\":\n",
    "        anti_corrupt_url=element_2.xpath(\"./@href\")[0]\n",
    "        index_year=re.findall(r\"\\d{3,}\",anti_corrupt_url)[0]\n",
    "        new_dict[year]=index_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020': '70337',\n",
       " '2019': '63283',\n",
       " '2018': '50083',\n",
       " '2017': '43675',\n",
       " '2016': '37334',\n",
       " '2015': '30984',\n",
       " '2014': '20156',\n",
       " '2013': '4786',\n",
       " '2012': '979',\n",
       " '2011': '857',\n",
       " '2009': '492'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entries(key,new_dict):\n",
    "    all_entries=[]\n",
    "    start=0\n",
    "    end=1\n",
    "    while find_entry(key,new_dict,start,end):\n",
    "        potat=find_entry(key,new_dict,start,end)\n",
    "        entries=create_dicts(potat['year'],potat['family_name'],potat['name'],potat['position'],potat['party_affiliation'],potat['url'],clean_text_details(potat['assets']))\n",
    "        start+=1\n",
    "        end+=1\n",
    "        all_entries.extend(entries)\n",
    "    return all_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method loops through each individual person/entry for each year. As such, it is highly inefficient as it stands. \n",
    "# Do not rerun this if you want to save time.\n",
    "# The reason why this method was chosen is because in order to get the full list of people, we need to use the AJAX url. The AJAX url unfortunately has no nested HTML structure at all, making xpath very difficult.\n",
    "all_entries=[]\n",
    "keys=['2020','2019','2018','2017','2016','2015','2014','2013','2012','2011']\n",
    "for key in keys:\n",
    "    entries=create_entries(key,new_dict)\n",
    "    all_entries.extend(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_df=pd.DataFrame(all_entries)\n",
    "output_df.to_csv(\"Russia_council_of_federation_anti_corruption.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is to extract foreign name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_russian_name(x):\n",
    "    root_person=\"http://declarator.org/person_report/\"\n",
    "    id_person=re.findall(r\"[0-9]+\",x)[0]\n",
    "    full_id_url=root_person+id_person+\"/\"\n",
    "    df_name=pd.read_excel(full_id_url)\n",
    "    return df_name['ФИО'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_3=pd.read_csv(\"Russia_council_of_federation_anti_corruption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_russian_names=[]\n",
    "for link in output_df_3.url.unique():\n",
    "    try: \n",
    "        list_of_russian_names.append(find_russian_name(link))\n",
    "    except:\n",
    "        list_of_russian_names.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_russian_name=pd.DataFrame({\"id\":output_df_3.url.unique(),\"russian_name\":list_of_russian_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_4=output_df_3.merge(df_russian_name,how=\"left\",right_on=\"id\",left_on=\"url\").drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing mojibakes\n",
    "import ftfy\n",
    "output_df_4.position=output_df_4.position.apply(lambda x: ftfy.fix_encoding(x) if x is not None else None)\n",
    "output_df_4.asset_value=output_df_4.asset_value.apply(lambda x: ftfy.fix_encoding(x) if x is not None else None)\n",
    "output_df_4.russian_name=output_df_4.russian_name.apply(lambda x: ftfy.fix_encoding(x) if x is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_4.to_csv(\"Russia_council_of_federation_anti_corruption_full.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
